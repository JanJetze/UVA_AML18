{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "The main idea of this assignment is to understand **Convolutional Neural Networks** and the basics of **image filtering**. We will implement matrix convolution as well as the convolutional layer from scratch.\n",
    "\n",
    "**Please note:**\n",
    "1. Please copy the code from the previous assignment (week 2) into a separate file `Blocks.py`. Make sure it resides in the same folder as this notebook. It should contain the implementation of the building blocks. \n",
    "2. All functions should be implemented using [**NumPy**](https://docs.scipy.org/doc/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "* [0. Before you begin](#0.-Before-you-begin)\n",
    "* [1. Recap](#1.-Recap)\n",
    "* [2. Matrix Convolution](#2.-Matrix-Convolution) (mandatory)\n",
    "* [3. Basic Kernels](#3.-Basic-Kernels) (mandatory)\n",
    "* [4. Convolutional Layer](#4.-Convolutional-Layer)\n",
    "* [5. MaxPooling Layer](#5.-MaxPooling-Layer) (mandatory)\n",
    "* [6. Flatten](#6.-Flatten)\n",
    "* [7. Experiments](#7.-Experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Before you begin\n",
    "\n",
    "Run the following block once when you start this notebook.  \n",
    "It imports [NumPy](https://docs.scipy.org/doc/), [Matplotlib](https://matplotlib.org/), AutoMark, and your `Blocks.py` implementations from last week.  \n",
    "We will make use of these imports during the course of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Blocks import *\n",
    "import automark as am\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in your studentnumber as your username again\n",
    "username = 'your_student_number'\n",
    "\n",
    "# get your progress by running this function\n",
    "am.get_progress(username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recap\n",
    "\n",
    "During the previous assignment, you implemented the main building blocks of neural networks:\n",
    "* **Dense Layer**\n",
    "* Non-linearity with ReLU\n",
    "* Loss functions\n",
    "* Optimization\n",
    "\n",
    "Dense layers can already be very useful. They perform the following mapping on the input matrix $X$ (matrix of objects) using the weights $W$: \n",
    "$$\n",
    "H = XW + b\n",
    "$$\n",
    "\n",
    "The dense layer enables creation and training of flexible models.\n",
    "\n",
    "Now, let's take a look at image processing using **Dense Layer**:\n",
    "1. We have a grayscale image $x$ of size $N \\times M$ (width & height)\n",
    "2. We reshape it into a vector of length $NM$\n",
    "3. Then we map it with a dense layer\n",
    "4. And obtain the transformed vector $y$\n",
    "\n",
    "Each element of $y$ depends on each element of $x$. That's why its also called **fully connected**.  \n",
    "A neural network which only consists of dense layers is therefore called a fully connected network.  \n",
    "\n",
    "When we work with images, we assume that each pixel is correlated with its neighbours and close pixels. Distant pixels are not correlated. Various experiments demonstrate that this assumption is correct.\n",
    "\n",
    "Dense layers captures these correlations, but they also capture *noisy* correlations to all other pixels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrix Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There is a way to create a **locally connected** layer which will learn local correlations using a smaller amount of parameters.  \n",
    "This layer is aptly called **Convolutional Layer** and is based on **matrix convolution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A picture is worth a thousand words which is especially true when learning about convolution:\n",
    "![Image convolution](https://camo.githubusercontent.com/709b7f5eb5203b41f9456f887787b6ea790878b5/68747470733a2f2f636f6d6d756e6974792e61726d2e636f6d2f6366732d66696c652f5f5f6b65792f636f6d6d756e6974797365727665722d626c6f67732d636f6d706f6e656e74732d7765626c6f6766696c65732f30302d30302d30302d32302d36362f343738362e636f6e762e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image convolution, a **filter**, also called **kernel**, is applied to the source matrix.  \n",
    "Each element from the kernel is multiplied by the corresponding element from the source matrix. The results are summed up and written to the target matrix.\n",
    "\n",
    "In this example, the output matrix has a smaller size than its source\\*. This is because the kernel can not overlap the borders. **Zero padding** can be used to retain the original dimension. It is a simple solution which involves adding a border of zeros to the input.\n",
    "\n",
    "\\* It may seem both matrices have the same size (both are shown with the same number of boxes. In the edges of the right matrix, however, no values are stored. The top-left corner of the right image starts where the $-3$ is placed.\n",
    "\n",
    "The source matrix $X$ is of size $N \\times M$ and the kernel $K$ is of size $(2p+1) \\times (2q +1 )$.  \n",
    "We define $X_{ij} = 0$ for $i > N, i < 1$ and $j > M, j < 1$.  \n",
    "In (other) words: If you try to access a pixel which is out of bounds assume that it is zero.  \n",
    "This is called **zero padding**.\n",
    "\n",
    "Therefore, the convolution of a matrix with a kernel is defined as follows:\n",
    "$$\n",
    "Y = X \\star K \\\\\n",
    "Y_{ij} = \\sum\\limits_{\\alpha=0}^{2p} \\sum\\limits_{\\beta=0}^{2q}\n",
    "K_{\\alpha \\beta} X_{i + \\alpha - p, j+\\beta - q}\n",
    "$$\n",
    "\n",
    "This operation's name depends on the field:\n",
    "* In machine learning: **convolution**\n",
    "* In mathematics: **cross-correlation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, its time for you to implement matrix convolution.  \n",
    "You can use the example below this code block to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_matrix(matrix, kernel):\n",
    "    \"\"\"Perform the convolution of the matrix \n",
    "        with the kernel using zero padding\n",
    "    # Arguments\n",
    "        matrix: input matrix np.array of size `(N, M)`\n",
    "        kernel: kernel of the convolution \n",
    "            np.array of size `(2p + 1, 2q + 1)`\n",
    "    # Output\n",
    "        the result of the convolution\n",
    "        np.array of size `(N, M)`\n",
    "    \"\"\"\n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    #################\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function with the following data:\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "2 & 3 & 4 \\\\\n",
    "3 & 4 & 5 \\\\\n",
    "\\end{bmatrix} \\quad\n",
    "K = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 2 \\\\\n",
    "\\end{bmatrix} \\quad \n",
    "X \\star K = \n",
    "\\begin{bmatrix}\n",
    "7 & 10 & 3 \\\\\n",
    "10 & 14 & 6 \\\\\n",
    "3 & 6 & 8 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We recreate the example data in Python to perform a local test run.  \n",
    "Don't be confused by [np.eye](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.eye.html). It fills our kernel matrix with ones on the diagonal from top-left to bottom-right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 3],\n",
    "    [2, 3, 4],\n",
    "    [3, 4, 5]\n",
    "])\n",
    "\n",
    "K = np.eye(3)\n",
    "K[-1, -1] = 2\n",
    "print(np.zeros(3))\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code block and compare the result with the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_matrix(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel confident with your solution, check it against the AutoMark-server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.test_student_function(username, conv_matrix, ['matrix', 'kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic Kernels\n",
    "\n",
    "Matrix convolution can be used to process an image (think Instagram): blur, shift, detecting edges, and much more.  \n",
    "This [article](http://setosa.io/ev/image-kernels/) (**recommended read**) about image kernels should give you a better understanding of convolutions. It happens to be interactive as well.\n",
    "\n",
    "In convolutional layers, the kernels are learned by training on the dataset. However, there are predefined kernels, for example used on your Instagram photos. Some examples are:\n",
    "\n",
    "**Sharpen Kernel:** \n",
    "$$ \n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 5 & -1 \\\\\n",
    "0 & -1 & 0 \n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "**Edge detection filter:**\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "-1 & -1 & -1 \\\\\n",
    "-1 & 8 & -1 \\\\\n",
    "-1 & -1 & -1 \n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "**Box blur of size 3:**\n",
    "$$ \\frac{1}{9}\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Let's play with convolutions by manipulating an image of a dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = plt.imread('./images/dog.png')\n",
    "plt.imshow(rgb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coloured images would require a 3-dimensional tensor to represent RGB (red, green, and blue).  \n",
    "Therefore, we will convert it to grayscale. This way it can be processed as a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb_img.mean(axis=2)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's blur the image with [box blur](https://en.wikipedia.org/wiki/Box_blur). It is just a convolution of a matrix with the kernel of size $N \\times N$ of the following form:\n",
    "\n",
    "$$\n",
    "\\frac{1}{N^2}\n",
    "\\begin{bmatrix}\n",
    "1 & \\dots  & 1\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "1 & \\dots  & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Every element of this filter is *one* and we divide the sum by the total amount of elements in the blur filter. You could understand it as taking the average of an image region.\n",
    "\n",
    "**Description:**  \n",
    "Perform the blur of the image.\n",
    "\n",
    "<u>Arguments:</u>\n",
    "* `image` - Input matrix - [np.array](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.array.html) of size `(N, M)`\n",
    "* `box_size` - Size of the blur kernel - `int > 0` the kernel is of size `(box_size, box_size)`\n",
    "\n",
    "<u>Output:</u>  \n",
    "The result of the blur [np.array](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.array.html) of size `(N, M)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_blur(image, box_size):\n",
    "    \"\"\"Perform the blur of the image\n",
    "    # Arguments\n",
    "        image: input matrix - np.array of size `(N, M)`\n",
    "        box_size: the size of the blur kernel - int > 0  \n",
    "            the kernel is of size `(box_size, box_size)`\n",
    "    # Output\n",
    "        the result of the blur\n",
    "            np.array of size `(N, M)`\n",
    "    \"\"\"   \n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    #################\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your solution before submitting it. Running the following code block should yield this result:\n",
    "$$ \n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "2 & 4 & 2 \\\\\n",
    "1 & 2 & 1 \n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([\n",
    "    [9, 0, 9],\n",
    "    [0, 0, 0],\n",
    "    [9, 0, 9]\n",
    "])\n",
    "\n",
    "print(box_blur(test_image, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.test_student_function(username, box_blur, ['image', 'box_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply your blur convolution on our dog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_dog = box_blur(img, box_size=5)\n",
    "plt.imshow(blur_dog, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will get the vertical and horizontal gradients. To perform it we calculate the convolution of the image with the following kernels:\n",
    "\n",
    "$$\n",
    "K_h = \n",
    "\\begin{bmatrix}\n",
    "-1 & 0  & 1\\\\\n",
    "\\end{bmatrix} \\quad\n",
    "K_v = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "-1\\\\\n",
    "\\end{bmatrix} \\\\\n",
    "X_h = X \\star K_h \\quad X_v = X \\star K_v\\\\\n",
    "$$\n",
    "\n",
    "And then we calculate the amplitude of the gradient:\n",
    "\n",
    "$$\n",
    "X_\\text{grad} = \\sqrt{X_h^2 + X_v^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_h = conv_matrix(blur_dog, np.array([[-1, 0, 1]]))\n",
    "dog_v = conv_matrix(blur_dog, np.array([[-1, 0, 1]]).T)\n",
    "dog_grad = np.sqrt(dog_h ** 2 + dog_v ** 2)\n",
    "plt.imshow(dog_grad, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields the edges of our blurred dog. It is not the only way to obtain edges though, there are plenty more:\n",
    "* [Canny edge detection](https://en.wikipedia.org/wiki/Canny_edge_detector)\n",
    "* [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "* [Prewitt operator](https://en.wikipedia.org/wiki/Prewitt_operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you convolve an image with a kernel you obtain a map of responses. The more correlated the patch of an image is with the kernel, the higher the response. Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 1, 1],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "# Create the image\n",
    "image = np.pad(pattern, [(12, 12), (10, 14)], mode='constant', constant_values=0)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('original image')\n",
    "plt.show()\n",
    "\n",
    "# Add some noise\n",
    "image = 0.5 * image + 0.5 * np.random.random(image.shape)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('noisy image')\n",
    "plt.show()\n",
    "\n",
    "# Let's find the cross \n",
    "response = conv_matrix(image, pattern)\n",
    "plt.imshow(response, cmap='gray')\n",
    "plt.title('local response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brightest pixel highlights where the cross is located. We can find the area where the image is locally close to the kernel. This is especially useful for finding different patterns in images such as: eyes, legs, dogs, cats, etc.\n",
    "\n",
    "We defined kernels and applied them to images. But we can also learn them by minimizing loss and making the processing as effective as possible. In order to do this, we have to define the **Convolutional Layer** in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convolutional Layer\n",
    "\n",
    "A **Convolutional Layer** works with images. Each image is a 3-dimensional object  $N_{\\text{channels}} \\times H \\times W$.  \n",
    "$Channels$ refers to the 3 colors (or 1 for black & white images), $H$ to height, and $W$ to width.  \n",
    "And therefore, the collection of images is 4-dimensional tensor of shape $N_{\\text{objects}} \\times N_{\\text{channels}} \\times H \\times W$.\n",
    "\n",
    "For example, 32 RGB images of size $224 \\times 224$ are represented as a tensor of shape $32 \\times 3 \\times 224 \\times 224$\n",
    "\n",
    "A convolutional layer receives an image as its input. Here is how it works:  \n",
    "The layer has `n_in * n_out` kernels. It is a tensor of size `(n_in, n_out, kernel_h, kernel_w)`  \n",
    "It takes a 4-dimensional tensor of size `n_objects, n_in, H, W` as its input. \n",
    "* `n_objects` is the collection of images. \n",
    "* Each of them has `n_in` channels.\n",
    "* The resolution of the images is `(H, W)`\n",
    "\n",
    "For each of the images the following operation is performed:  \n",
    "* In order to get the 1st output channel, all inputs are convolved with their corresponding kernels.  \n",
    "* Then the results are summed and written to the output channel.  \n",
    "This is our implementation:\n",
    "```python\n",
    "for i in range(n_out):\n",
    "    out_channel = 0.0\n",
    "    for j in range(n_in):\n",
    "        kernel_2d = K[i, j] # Retrieve kernel from the collection of kernels\n",
    "        input_channel = input_image[j] # Get one channel of the input iamge\n",
    "        out_channel += conv_matrix(input_channel, kernel_2d) # Perform convolution\n",
    "    output_image.append(out_channel) # Append the calculated channel to the output          \n",
    "```\n",
    "\n",
    "We implemented the convolutional layer for you. The implementation of `backward` is based on the idea that convolution could be represented as matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Layer. The implementation is based on \n",
    "        the representation of the convolution as matrix multiplication\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, n_out, filter_size):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.W = np.random.normal(size=(n_out, n_in, filter_size, filter_size))\n",
    "        self.b = np.zeros(n_out)\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        n_obj, n_in, h, w = x_input.shape\n",
    "        n_out = len(self.W)\n",
    "        \n",
    "        self.output = []\n",
    "        \n",
    "        for image in x_input:\n",
    "            output_image = []\n",
    "            for i in range(n_out):\n",
    "                out_channel = 0.0\n",
    "                for j in range(n_in):\n",
    "                    out_channel += conv_matrix(image[j], self.W[i, j])\n",
    "                output_image.append(out_channel)\n",
    "            self.output.append(np.stack(output_image, 0))\n",
    "\n",
    "        self.output = np.stack(self.output, 0)\n",
    "        return self.output\n",
    "\n",
    "    \n",
    "    def backward(self, x_input, grad_output):\n",
    "\n",
    "        N, C, H, W = x_input.shape \n",
    "        F, C, HH, WW = self.W.shape\n",
    "        \n",
    "        pad = int((HH - 1) / 2)\n",
    "\n",
    "        self.grad_b = np.sum(grad_output, (0, 2, 3)) \n",
    "\n",
    "        # pad input array\n",
    "        x_padded = np.pad(x_input, ((0,0), (0,0), (pad, pad), (pad, pad)), 'constant')\n",
    "        H_padded, W_padded = x_padded.shape[2], x_padded.shape[3]\n",
    "        # naive implementation of im2col\n",
    "        x_cols = None\n",
    "        for i in range(HH, H_padded + 1):\n",
    "            for j in range(WW, W_padded+1):\n",
    "                for n in range(N):\n",
    "                    field = x_padded[n, :, i-HH:i, j-WW:j].reshape((1,-1))    \n",
    "                    if x_cols is None:\n",
    "                        x_cols = field\n",
    "                    else:\n",
    "                        x_cols = np.vstack((x_cols, field))\n",
    "                        \n",
    "        x_cols = x_cols.T\n",
    "\n",
    "        d_out = grad_output.transpose(1, 2, 3, 0) \n",
    "        dout_cols = d_out.reshape(F, -1) \n",
    "\n",
    "        dw_cols = np.dot(dout_cols, x_cols.T) \n",
    "        self.grad_W = dw_cols.reshape(F, C, HH, WW) \n",
    "\n",
    "        w_cols = self.W.reshape(F, -1) \n",
    "        dx_cols = np.dot(w_cols.T, dout_cols) \n",
    "\n",
    "        dx_padded = np.zeros((N, C, H_padded, W_padded))\n",
    "        idx = 0\n",
    "        for i in range(HH, H_padded + 1):\n",
    "            for j in range(WW, W_padded + 1):\n",
    "                for n in range(N):\n",
    "                    dx_padded[n:n+1, :, i-HH:i, j-WW:j] += dx_cols[:, idx].reshape((1, C, HH, WW))\n",
    "                    idx += 1\n",
    "            dx = dx_padded[:, :, pad:-pad, pad:-pad]\n",
    "        grad_input = dx\n",
    "        return grad_input\n",
    "    \n",
    "    def get_params(self):\n",
    "        return [self.W, self.b]\n",
    "\n",
    "    def get_params_gradients(self):\n",
    "        return [self.grad_W, self.grad_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer transforms images with 3 channels into images with 8 channels by convolving them with kernels of size `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = ConvLayer(3, 8, filter_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Pooling Layer\n",
    "\n",
    "The pooling layer **reduces the size of an image**. \n",
    "\n",
    "In the following figure $2 \\times 2$ pooling is applied on the image which effectively reduces the size by half.  \n",
    "If you look closely, pooling operations have no effect on the depth of an image.\n",
    "![pool](./src/pool.png)\n",
    "\n",
    "There are several types of pooling operations but the most common one is **max pooling**. \n",
    "\n",
    "During a max pooling operation, the image is split into **windows** (or **filters**) and then the maximum of each window is used as the output.\n",
    "\n",
    "![maxpool](./src/maxpool.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_forward(x_input):\n",
    "    \"\"\"Perform max pooling operation with 2x2 window\n",
    "    # Arguments\n",
    "        x_input: np.array of size (2 * W, 2 * H)\n",
    "    # Output\n",
    "        output: np.array of size (W, H)\n",
    "    \"\"\"\n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    ################# \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, you can use example data to test your solution:  \n",
    "**Image:**\n",
    "$$ \n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 2 & 4 \\\\\n",
    "5 & 6 & 7 & 8 \\\\\n",
    "3 & 2 & 1 & 0 \\\\\n",
    "1 & 2 & 3 & 4\n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "**Output:**\n",
    "$$ \n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "6 & 8 \\\\\n",
    "3 & 4\n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([\n",
    "    [1, 1, 2, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [3, 2, 1, 0],\n",
    "    [1, 2, 3, 4]\n",
    "])\n",
    "\n",
    "print(maxpool_forward(test_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your solution once you are confident it is implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.test_student_function(username, maxpool_forward, ['x_input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already implemented the gradient calculation.  \n",
    "It is not overly complicated; reading the code should help you to understand the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_grad_input(x_input, grad_output):\n",
    "    \"\"\"Calculate partial derivative of the loss with respect to the input\n",
    "    # Arguments\n",
    "        x_input: np.array of size (2 * W, 2 * H)\n",
    "        grad_output: partial derivative of the loss \n",
    "            with respect to the output \n",
    "            np.array of size (W, H)\n",
    "    # Output\n",
    "        output: partial derivative of the loss \n",
    "            with respect to the input\n",
    "            np.array of size (2 * W, 2 * H) \n",
    "    \"\"\"\n",
    "    height, width = x_input.shape\n",
    "    # Create an array of zeros the same size as the input\n",
    "    grad_input = np.zeros(x_input.shape)\n",
    "    \n",
    "    # We set 1 if the element is the maximum in its window\n",
    "    for i in range(0, height, 2):\n",
    "        for j in range(0, width, 2):\n",
    "            window = x_input[i:i+2, j:j+2]\n",
    "            i_max, j_max = np.unravel_index(np.argmax(window), (2, 2))\n",
    "            grad_input[i + i_max, j + j_max] = 1\n",
    "            \n",
    "    # Overwrite with the corresponding gradient instead of 1       \n",
    "    grad_input = grad_input.ravel()\n",
    "    grad_input[grad_input == 1] = grad_output.ravel()\n",
    "    grad_input = grad_input.reshape(x_input.shape)\n",
    "    return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following up is the full implementation of the **MaxPool Layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2x2(Layer):\n",
    "    \n",
    "    def forward(self, x_input):\n",
    "        n_obj, n_ch, h, w = x_input.shape\n",
    "        self.output = np.zeros((n_obj, n_ch, h // 2, w // 2))\n",
    "        for i in range(n_obj):\n",
    "            for j in range(n_ch):\n",
    "                self.output[i, j] = maxpool_forward(x_input[i, j])\n",
    "        return self.output \n",
    "    \n",
    "    def backward(self, x_input, grad_output):\n",
    "        n_obj, n_ch, _, _ = x_input.shape\n",
    "        grad_input = np.zeros_like(x_input)\n",
    "        for i in range(n_obj):\n",
    "            for j in range(n_ch):\n",
    "                grad_input[i, j] = maxpool_grad_input(x_input[i, j], grad_output[i, j])\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Flatten\n",
    "\n",
    "Convolutional neural networks are better at image processing than fully connected neural networks (dense networks). We will combine convolutional layers, which deal with 4-dimensional tensors, with dense layers, which work with matrices.  \n",
    "In order to bridge the gap between convolutional layers and dense layers we will implement the **Flatten Layer**.\n",
    "\n",
    "The Flatten layer receives a 4-dimensional tensor of size `(n_obj, n_channels, h, w)` as its input and reshapes it into a 2-dimensional tensor (matrix) of size `(n_obj, n_channels * h * w)`.  \n",
    "\n",
    "The backward pass of this layer is pretty straightforward. Remember that we don't actually change any values; we merely reshape inputs.\n",
    "\n",
    "**Please implement `flatten_forward` and `flatten_grad_input` functions using [np.reshape](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.reshape.html)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_forward(x_input):\n",
    "    \"\"\"Perform the reshaping of the tensor of size `(K, L, M, N)` \n",
    "        to the tensor of size `(K, L*M*N)`\n",
    "    # Arguments\n",
    "        x_input: np.array of size `(K, L, M, N)`\n",
    "    # Output\n",
    "        output: np.array of size `(K, L*M*N)`\n",
    "    \"\"\"\n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    #################\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use test data and compare the final shape. It should be `(100, 768)` for the following example.  \n",
    "Please ignore the use of [np.zeros](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.zeros.html) in this case. We are just interested in transforming shapes.  \n",
    "**Be aware:** This test will fail if you do not return an array like object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.zeros((100, 3, 16, 16))\n",
    "\n",
    "print(flatten_forward(test_input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.test_student_function(username, flatten_forward, ['x_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_grad_input(x_input, grad_output):\n",
    "    \"\"\"Calculate partial derivative of the loss with respect to the input\n",
    "    # Arguments\n",
    "        x_input: partial derivative of the loss \n",
    "            with respect to the output\n",
    "            np.array of size `(K, L*M*N)`\n",
    "    # Output\n",
    "        output: partial derivative of the loss \n",
    "            with respect to the input\n",
    "            np.array of size `(K, L, M, N)`\n",
    "    \"\"\"\n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    #################\n",
    "    return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, submit your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am.test_student_function(username, flatten_grad_input, ['x_input', 'grad_output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the, pretty self-explanatory, implemention of the **Flatten Layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    \n",
    "    def forward(self, x_input):\n",
    "        self.output = flatten_forward(x_input)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, x_input, grad_output):\n",
    "        output = flatten_grad_input(x_input, grad_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Experiments\n",
    "\n",
    "This chapter focuses on conducting several experiments. We will train our neural networks with **mini-batches**. Mini-batches are small portions of our dataset, all mini-batches together should form the original dataset again. With our mini-batches in place we will feed these one-by-one to our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def iterate_minibatches(x, y, batch_size=16, verbose=True):\n",
    "    assert len(x) == len(y)\n",
    "    \n",
    "    indices = np.arange(len(x))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for i, start_idx in enumerate(range(0, len(x) - batch_size + 1, batch_size)):\n",
    "        if verbose:\n",
    "            print('\\rBatch: {}/{}'.format(i + 1, len(x) // batch_size), end='')\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        excerpt = indices[start_idx:start_idx + batch_size]\n",
    "        yield x[excerpt], y[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's import the data. Please [download](http://yann.lecun.com/exdb/mnist/) it first.\n",
    "\n",
    "If you get an error with loading the data, chances are you'll need to unpack the downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(load_mnist(dataset='training', path='.'))\n",
    "train\n",
    "train_images = np.array([im[1] for im in train])\n",
    "train_targets = np.array([im[0] for im in train])\n",
    "# We will train a 0 vs. 1 classifier\n",
    "x_train = train_images[train_targets < 2][:1000]\n",
    "y_train = train_targets[train_targets < 2][:1000]\n",
    "\n",
    "y_train = y_train * 2 - 1\n",
    "y_train = y_train.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just loaded the MNIST dataset. This dataset consists of gray-scale (so a single channel) images of size `28x28`. These images are represented by the RGB color model. This color model representes a color by 3 integers that range from 0 to 255, or in the case of gray-scale images this is a single integer. This means that each picture in the MNIST dataset is represented by 784 pixels with a value ranging from 0 to 255. This is how a single image looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0].reshape(28, 28), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make divergence to an optimum easier, we will normalize the images to have values between 0 and 1. Then, by reshaping, we will add the dimensions for the channel which, for simplicity, was removed by the creators of this dataset. As you can see, this doesn't change anything in how the image looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((-1, 1, 28, 28))\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train a simple convolutional neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn():\n",
    "    nn = SequentialNN()\n",
    "\n",
    "    nn.add(ConvLayer(1, 2, filter_size=3)) # The output is of size N_obj 2 28 28\n",
    "    nn.add(ReLU()) # The output is of size N_obj 2 28 28\n",
    "    nn.add(MaxPool2x2()) # The output is of size N_obj 2 14 14\n",
    "\n",
    "    nn.add(ConvLayer(2, 4, filter_size=3)) # The output is of size N_obj 4 14 14\n",
    "    nn.add(ReLU()) # The output is of size N_obj 4 14 14\n",
    "    nn.add(MaxPool2x2()) # The output is of size N_obj 4 7 7\n",
    "\n",
    "    nn.add(FlattenLayer()) # The output is of size N_obj 196\n",
    "    nn.add(Dense(4 * 7 * 7, 32))\n",
    "    nn.add(ReLU())\n",
    "    nn.add(Dense(32, 1))\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = get_cnn()\n",
    "loss = Hinge()\n",
    "optimizer = SGD(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will train for about 5 minutes\n",
    "num_epochs = 5 \n",
    "batch_size = 32\n",
    "# We will store the results here\n",
    "history = {'loss': [], 'accuracy': []}\n",
    "\n",
    "# `num_epochs` represents the number of iterations\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "    \n",
    "    # We perform iteration a one-by-one iteration of the mini-batches\n",
    "    for x_batch, y_batch in iterate_minibatches(x_train, y_train, batch_size):\n",
    "        # Predict the target value\n",
    "        y_pred = nn.forward(x_batch)\n",
    "        # Compute the gradient of the loss\n",
    "        loss_grad = loss.backward(y_pred, y_batch)\n",
    "        # Perform backwards pass\n",
    "        nn.backward(x_batch, loss_grad)\n",
    "        # Update the params\n",
    "        optimizer.update_params()\n",
    "        \n",
    "        # Save loss and accuracy values\n",
    "        history['loss'].append(loss.forward(y_pred, y_batch))\n",
    "        prediction_is_correct = (y_pred > 0) == (y_batch > 0)\n",
    "        history['accuracy'].append(np.mean(prediction_is_correct))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the results to get a better insight\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "ax_1 = plt.subplot()\n",
    "ax_1.plot(history['loss'], c='g', lw=2, label='train loss')\n",
    "ax_1.set_ylabel('loss', fontsize=16)\n",
    "ax_1.set_xlabel('#batches', fontsize=16)\n",
    "\n",
    "ax_2 = plt.twinx(ax_1)\n",
    "ax_2.plot(history['accuracy'], lw=3, label='train accuracy')\n",
    "ax_2.set_ylabel('accuracy', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things you could try:**  \n",
    "Train the model with a different `batch_size`:\n",
    "* What would happen with `batch_size=1`?\n",
    "* What would happen with `batch_size=1000`?\n",
    "* Does the speed of the computation depend on this parameter? If so, why?\n",
    "\n",
    "Train the model with a different number of `num_epochs`:\n",
    "* What would happen with `num_epochs=1`?\n",
    "* What would happen with `num_epochs=1000`?\n",
    "* How does it affect computation time, resource strain, and accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the activations of the intermediate layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_images = x_batch[:2]\n",
    "_ = nn.forward(viz_images)\n",
    "\n",
    "activations = {\n",
    "    'conv_1': nn.layers[0].output,\n",
    "    'relu_1': nn.layers[1].output,\n",
    "    'pool_1': nn.layers[2].output,\n",
    "    'conv_2': nn.layers[3].output,\n",
    "    'relu_2': nn.layers[4].output,\n",
    "    'pool_2': nn.layers[5].output,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(4, 8))\n",
    "\n",
    "ax1.imshow(viz_images[0, 0], cmap=plt.cm.gray_r)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "ax2.imshow(viz_images[1, 0], cmap=plt.cm.gray_r)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of Conv 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv 1\n",
    "f, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['conv_1'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of ReLU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU 1\n",
    "f, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['relu_1'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of MaxPooling 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling 1\n",
    "f, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['pool_1'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of Conv 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv 2\n",
    "f, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['conv_2'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of ReLU 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU 2\n",
    "f, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['relu_2'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of MaxPooling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling 2\n",
    "f, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['pool_2'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we go deeper and deeper, images become less locally-correlated (the dependance between two neighbours decreases) and more semantically loaded.  \n",
    "Each convoluted pixel stores more and more useful information about the object.  \n",
    "In the end, this will be anaylzed using several **Dense Layers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things you could try:**\n",
    "* Change the architecture of the neural network\n",
    "* Vary the number of kernels\n",
    "* Vary the size of the kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
